import torch
from datasets import load_dataset
from transformers import ViTImageProcessor, ViTForImageClassification, TrainingArguments, Trainer
import numpy as np
from sklearn.metrics import accuracy_score
import os
import matplotlib.pyplot as plt

# --- 1. AYARLAR ---
DATASET_PATH = r"C:\Users\THERMALTAKE\Desktop\bird\archive" 
MODEL_NAME = "google/vit-base-patch16-224"
OUTPUT_DIR = "./bird_vit_model_cikti"
EPOCHS = 10
BATCH_SIZE = 16 

# --- 2. GPU KONTROLÃœ ---
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"\nðŸ“¢ KullanÄ±lan Cihaz: {device.upper()}")
if device == "cuda":
    print(f"âœ… Ekran KartÄ±: {torch.cuda.get_device_name(0)}")

# --- 3. VERÄ° SETÄ°NÄ° YÃœKLEME ---
print(f"\nðŸ“‚ Veri seti okunuyor: {DATASET_PATH}")
ds = load_dataset("imagefolder", data_dir=DATASET_PATH)
ds = ds['train'].train_test_split(test_size=0.2, seed=42)

labels = ds['train'].features['label'].names
label2id = {label: str(i) for i, label in enumerate(labels)}
id2label = {str(i): label for i, label in enumerate(labels)}

print(f"ðŸ“Š Toplam SÄ±nÄ±f SayÄ±sÄ±: {len(labels)}")

# --- 4. Ã–N Ä°ÅžLEME ---
processor = ViTImageProcessor.from_pretrained(MODEL_NAME)

def transform(example_batch):
    # Bu fonksiyon artÄ±k remove_unused_columns=False sayesinde 'image' sÃ¼tununu gÃ¶rebilecek.
    # Yine de dinamik olarak anahtarÄ± bulalÄ±m:
    keys = list(example_batch.keys())
    image_key = next((k for k in keys if k != 'label'), None)
    
    if image_key is None:
        # Bu hata artÄ±k Ã§Ä±kmamalÄ±, ama gÃ¼venlik iÃ§in kalsÄ±n
        raise ValueError(f"âŒ HATA: Resim sÃ¼tunu silinmiÅŸ! Gelen anahtarlar: {keys}")

    # Resimleri iÅŸlemden geÃ§irip (pixel_values) oluÅŸturuyoruz
    inputs = processor([x.convert("RGB") for x in example_batch[image_key]], return_tensors='pt')
    
    # Etiketleri de ekliyoruz
    inputs['labels'] = example_batch['label']
    
    return inputs

prepared_ds = ds.with_transform(transform)

# --- 5. MODELÄ° HAZIRLAMA ---
model = ViTForImageClassification.from_pretrained(
    MODEL_NAME,
    num_labels=len(labels),
    id2label=id2label,
    label2id=label2id,
    ignore_mismatched_sizes=True
)
model.to(device)

# --- 6. METRÄ°K ---
def compute_metrics(p):
    predictions, labels = p
    predictions = np.argmax(predictions, axis=1)
    acc = accuracy_score(labels, predictions)
    return {"accuracy": acc}

# --- 7. EÄžÄ°TÄ°M AYARLARI (KRÄ°TÄ°K DÃœZELTME BURADA) ---
training_args = TrainingArguments(
    output_dir=OUTPUT_DIR,
    per_device_train_batch_size=BATCH_SIZE,
    per_device_eval_batch_size=BATCH_SIZE,
    num_train_epochs=EPOCHS,
    learning_rate=2e-5,
    weight_decay=0.01,
    
    # --- Ä°ÅžTE Ã‡Ã–ZÃœM: ---
    remove_unused_columns=False, # Trainer'Ä±n 'image' sÃ¼tununu silmesini engeller!
    # -------------------
    
    eval_strategy="epoch",       
    save_strategy="epoch",
    load_best_model_at_end=True,
    fp16=True,                   
    dataloader_num_workers=0,    
    logging_steps=50,
    report_to="none"
)

# --- 8. BAÅžLAT ---
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=prepared_ds["train"],
    eval_dataset=prepared_ds["test"],
    processing_class=processor, 
    compute_metrics=compute_metrics,
    
    # Verileri birleÅŸtirirken hata olmasÄ±n diye Ã¶zel collator
    data_collator=None 
)

print("\nðŸ EÄŸitim BaÅŸlÄ±yor...")
trainer.train()

# --- 9. KAYIT ---
print(f"\nðŸ’¾ Model kaydediliyor: {OUTPUT_DIR}")
trainer.save_model(OUTPUT_DIR)
processor.save_pretrained(OUTPUT_DIR)

# Grafikler
history = trainer.state.log_history
train_loss = [x['loss'] for x in history if 'loss' in x]
eval_loss = [x['eval_loss'] for x in history if 'eval_loss' in x]
eval_acc = [x['eval_accuracy'] for x in history if 'eval_accuracy' in x]

plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(train_loss, label='Training Loss')
if len(eval_loss) > 0:
    plt.plot(np.linspace(0, len(train_loss), len(eval_loss)), eval_loss, label='Validation Loss')
plt.title('KayÄ±p (Loss)')
plt.legend()

plt.subplot(1, 2, 2)
if len(eval_acc) > 0:
    plt.plot(eval_acc, label='Validation Accuracy', color='green')
plt.title('DoÄŸruluk (Accuracy)')
plt.legend()

plt.savefig('egitim_sonuclari.png')
print("ðŸ“ˆ Grafik kaydedildi.")
plt.show()